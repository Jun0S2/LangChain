# Linkedin í”„ë¡œí•„ ì •ë³´ scrapping
import os  # í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©ì„ ìœ„í•œ OS ëª¨ë“ˆ
import requests  # HTTP ìš”ì²­ì„ ë³´ë‚¼ ë•Œ ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv  # í™˜ê²½ ë³€ìˆ˜(.env íŒŒì¼) ë¡œë“œ

# ğŸ”¹ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.envì—ì„œ API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•¨)
load_dotenv()

# ğŸ“Œ LinkedIn í”„ë¡œí•„ ì •ë³´ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ëŠ” í•¨ìˆ˜
def scrape_linkedin_profile(linkedin_profile_url: str, mock: bool = False):
    """
    LinkedIn í”„ë¡œí•„ í˜ì´ì§€ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜.
    - mock=True: ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹  ë¯¸ë¦¬ ì €ì¥ëœ JSON íŒŒì¼ì„ ë¶ˆëŸ¬ì˜´ (í…ŒìŠ¤íŠ¸ ìš©ë„)
    - mock=False: Proxycurl APIë¥¼ ì‚¬ìš©í•˜ì—¬ LinkedIn ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
    """

    if mock:
        # ğŸ”¹ í…ŒìŠ¤íŠ¸ìš© JSON ë°ì´í„° ì‚¬ìš©
        linkedin_profile_url = "https://gist.githubusercontent.com/emarco177/.../eden-marco.json"
        response = requests.get(linkedin_profile_url, timeout=10)
    else:
        # ğŸ”¹ ì‹¤ì œ Proxycurl APIë¥¼ ì‚¬ìš©í•˜ì—¬ LinkedIn í”„ë¡œí•„ ë°ì´í„° ìš”ì²­
        api_endpoint = "https://nubela.co/proxycurl/api/v2/linkedin"
        header_dic = {"Authorization": f'Bearer {os.environ.get("PROXYCURL_API_KEY")}'}
        response = requests.get(
            api_endpoint,
            headers=header_dic,
            params={"url": linkedin_profile_url},
            timeout=10,
        )

    # ğŸ”¹ API ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    data = response.json()

    # ğŸ”¹ ë¶ˆí•„ìš”í•œ í•­ëª© ì œê±° (ë¹ˆ ê°’ ë° íŠ¹ì • í•„ë“œ)
    data = {
        k: v for k, v in data.items()
        if v not in ([], "", None) and k not in ["people_also_viewed", "certifications"]
    }

    # ğŸ”¹ ê·¸ë£¹ ì •ë³´ì—ì„œ í”„ë¡œí•„ ì´ë¯¸ì§€ URL ì œê±°
    if data.get("groups"):
        for group_dict in data.get("groups"):
            group_dict.pop("profile_pic_url")

    return data


# ğŸ”¹ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    linkedin_profile_url = "https://www.linkedin.com/in/eden-marco/"
    scrape_linkedin_profile(linkedin_profile_url)
